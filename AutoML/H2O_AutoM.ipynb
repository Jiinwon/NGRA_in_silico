{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fancyycode/AUTOML_H2O/blob/main/H2O_AutoML_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WSrSrK3aga0c",
    "outputId": "6acf4a7e-5771-403d-c67e-724a80408fab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting h2o\n",
      "  Downloading h2o-3.46.0.4.tar.gz (265.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.3/265.3 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: rdkit in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (2023.9.6)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from h2o) (2.31.0)\n",
      "Collecting tabulate (from h2o)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from requests->h2o) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from requests->h2o) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from requests->h2o) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from requests->h2o) (2024.2.2)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Building wheels for collected packages: h2o\n",
      "  Building wheel for h2o (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for h2o: filename=h2o-3.46.0.4-py2.py3-none-any.whl size=265375577 sha256=1b75f126cc091509b2a5a5b929a303b837d13bf40d9d07ae88a7e5b6b2071390\n",
      "  Stored in directory: /Users/hwangjin-won/Library/Caches/pip/wheels/4d/a6/47/8bfeb1026fd65cb8630beb74d8e3bec844f572cf4f336fdd56\n",
      "Successfully built h2o\n",
      "Installing collected packages: tabulate, h2o\n",
      "Successfully installed h2o-3.46.0.4 tabulate-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install h2o scikit-learn matplotlib rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iVOOGmW-rIZG",
    "outputId": "993c9bab-1ede-435d-e5ae-2fd204a71fde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>22 days 0 hours 58 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Seoul</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 14 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_hwangjin_won_srt9on</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.436 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.12.4 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------------\n",
       "H2O_cluster_uptime:         22 days 0 hours 58 mins\n",
       "H2O_cluster_timezone:       Asia/Seoul\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.3\n",
       "H2O_cluster_version_age:    1 month and 14 days\n",
       "H2O_cluster_name:           H2O_from_python_hwangjin_won_srt9on\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.436 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.12.4 final\n",
       "--------------------------  -----------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/tg414.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 171\u001b[0m\n\u001b[1;32m    168\u001b[0m     h2o_manager\u001b[38;5;241m.\u001b[39mshutdown()\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 171\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 143\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    140\u001b[0m h2o_manager\u001b[38;5;241m.\u001b[39minitialize()\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Example data load\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/data/tg414.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m data_processor \u001b[38;5;241m=\u001b[39m DataProcessor(data)\n\u001b[1;32m    146\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m data_processor\u001b[38;5;241m.\u001b[39msplit_data()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.1/libexec/lib/python3.12/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/tg414.csv'"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from h2o.frame import H2OFrame\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, classification_report\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys, AllChem, RDKFingerprint\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class H2OManager:\n",
    "    def __init__(self):\n",
    "        self.h2o_instance = None\n",
    "\n",
    "    def initialize(self):\n",
    "        \"\"\"Initialize the H2O cluster.\"\"\"\n",
    "        self.h2o_instance = h2o.init()\n",
    "\n",
    "    def shutdown(self):\n",
    "        \"\"\"Shutdown the H2O cluster.\"\"\"\n",
    "        h2o.shutdown()\n",
    "\n",
    "class FingerprintGenerator:\n",
    "    def __init__(self, fingerprint_type):\n",
    "        self.fingerprint_type = fingerprint_type\n",
    "\n",
    "    def generate(self, mol):\n",
    "        \"\"\"Generate a fingerprint for a given molecule.\"\"\"\n",
    "        if not mol:\n",
    "            return None\n",
    "        if self.fingerprint_type == 'MACCS':\n",
    "            return MACCSkeys.GenMACCSKeys(mol)\n",
    "        elif self.fingerprint_type == 'Morgan':\n",
    "            return AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "        elif self.fingerprint_type == 'RDKit':\n",
    "            return RDKFingerprint(mol)\n",
    "        elif self.fingerprint_type == 'Layered':\n",
    "            return AllChem.LayeredFingerprint(mol)\n",
    "        elif self.fingerprint_type == 'Pattern':\n",
    "            return AllChem.PatternFingerprint(mol)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported fingerprint type: {self.fingerprint_type}\")\n",
    "\n",
    "    def generate_from_smiles(self, smiles_list, activities):\n",
    "        \"\"\"Generate fingerprints for the given SMILES list.\"\"\"\n",
    "        fingerprints = []\n",
    "        valid_activities = []\n",
    "        for smiles, activity in zip(smiles_list, activities):\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is None:\n",
    "                print(f\"Invalid SMILES: {smiles}\")\n",
    "                continue\n",
    "            fp = self.generate(mol)\n",
    "            if fp is not None:\n",
    "                fingerprints.append(fp.ToBitString())\n",
    "                valid_activities.append(activity)\n",
    "        return fingerprints, valid_activities\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def split_data(self):\n",
    "        \"\"\"Split the data into training and testing sets.\"\"\"\n",
    "        y = self.data['Toxicity'].values\n",
    "        X = self.data['SMILES'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    @staticmethod\n",
    "    def create_h2o_frame(fingerprints, activities):\n",
    "        \"\"\"Create an H2O frame from the given fingerprints and activities.\"\"\"\n",
    "        data_dict = {\n",
    "            'Mol': fingerprints,\n",
    "            'Activity': activities\n",
    "        }\n",
    "        return H2OFrame(pd.DataFrame(data_dict))\n",
    "\n",
    "class AutoMLRunner:\n",
    "    def __init__(self, max_models=20, seed=1):\n",
    "        self.max_models = max_models\n",
    "        self.seed = seed\n",
    "        self.automl = H2OAutoML(max_models=self.max_models, seed=self.seed, balance_classes=True)\n",
    "\n",
    "    def run(self, fingerprints, activities):\n",
    "        \"\"\"Run H2O AutoML on the given fingerprints and activities.\"\"\"\n",
    "        h2o_frame = DataProcessor.create_h2o_frame(fingerprints, activities)\n",
    "        h2o_frame['Activity'] = h2o_frame['Activity'].asfactor()  # Convert to categorical for classification\n",
    "        target_column = \"Activity\"\n",
    "        feature_columns = ['Mol']\n",
    "        self.automl.train(x=feature_columns, y=target_column, training_frame=h2o_frame)\n",
    "        return self.automl\n",
    "\n",
    "    def evaluate_and_save_model(self, automl, test_data, save_directory):\n",
    "        \"\"\"Evaluate the best model and save its performance metrics and plots.\"\"\"\n",
    "        best_model = automl.leader\n",
    "        performance = best_model.model_performance(test_data)\n",
    "        print(\"Performance on test data:\", performance)\n",
    "\n",
    "        # Calculate classification report\n",
    "        predictions = best_model.predict(test_data)\n",
    "        y_true = test_data['Activity'].as_data_frame()['Activity']\n",
    "        y_pred = predictions[\"predict\"].as_data_frame()['predict']\n",
    "        report = classification_report(y_true, y_pred, output_dict=True)\n",
    "\n",
    "        # Save metadata\n",
    "        metadata = {\n",
    "            \"model_path\": save_directory,\n",
    "            \"params\": best_model.get_params(),\n",
    "            \"performance\": performance.rmse(),\n",
    "            \"classification_report\": report,\n",
    "            \"timestamp\": (datetime.now(timezone(timedelta(hours=9)))).strftime(\"%Y%m%d_%H%M%S\")  # KST\n",
    "        }\n",
    "        metadata_path = os.path.join(save_directory, \"metadata.json\")\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(metadata, f)\n",
    "        print(f\"Metadata saved to: {metadata_path}\")\n",
    "\n",
    "        # Plot and save ROC curve\n",
    "        fpr, tpr, _ = roc_curve(test_data['Activity'].as_data_frame(), predictions[\"p1\"].as_data_frame())\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:0.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(os.path.join(save_directory, \"roc_curve.png\"))\n",
    "        plt.show()\n",
    "\n",
    "def main():\n",
    "    h2o_manager = H2OManager()\n",
    "    h2o_manager.initialize()\n",
    "\n",
    "    # Example data load\n",
    "    data = pd.read_csv('/data/tg414.csv')\n",
    "    data_processor = DataProcessor(data)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = data_processor.split_data()\n",
    "\n",
    "    # Generate MACCS fingerprints\n",
    "    fingerprint_generator = FingerprintGenerator('MACCS')\n",
    "    train_fingerprints, y_train = fingerprint_generator.generate_from_smiles(X_train, y_train)\n",
    "    test_fingerprints, y_test = fingerprint_generator.generate_from_smiles(X_test, y_test)\n",
    "\n",
    "    # Run AutoML\n",
    "    automl_runner = AutoMLRunner()\n",
    "    automl = automl_runner.run(train_fingerprints, y_train)\n",
    "\n",
    "    # Create directory for saving model and results\n",
    "    current_time = datetime.now(timezone(timedelta(hours=9))).strftime(\"%Y%m%d_%H%M%S\")  # KST\n",
    "    save_directory = os.path.join(\"models\", current_time)\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    # Evaluate and save model\n",
    "    test_data_h2o = DataProcessor.create_h2o_frame(test_fingerprints, y_test)\n",
    "    test_data_h2o['Activity'] = test_data_h2o['Activity'].asfactor()  # Convert to categorical for classification\n",
    "    automl_runner.evaluate_and_save_model(automl, test_data_h2o, save_directory)\n",
    "\n",
    "    # Shutdown H2O cluster\n",
    "    h2o_manager.shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bEZgGEY4g9Q",
    "outputId": "1a3e32ed-4b7a-4a7b-cb0c-a053273d820d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CasRN           DTXSID  \\\n",
      "0  24347-58-8  DTXSID801031371   \n",
      "1   5341-95-7  DTXSID301031540   \n",
      "2    108-32-7    DTXSID2026789   \n",
      "3  56554-53-1   DTXSID10971994   \n",
      "4  13241-33-3   DTXSID60927668   \n",
      "\n",
      "                                              SMILES  Toxicity  \n",
      "0                               C[C@@H](O)[C@@H](C)O         0  \n",
      "1                                C[C@@H](O)[C@H](C)O         0  \n",
      "2                                       CC1COC(=O)O1         0  \n",
      "3  CC(CC(=O)OCC(COC(=O)CC(C)CC(C)(C)C)OC(=O)CC(C)...         0  \n",
      "4  [H][C@@]1(O[C@@H]2[C@@H](O)[C@H](O)[C@@H](CO)O...         0  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/H2O_AutoML/tg414.csv')\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8RCJDwPr8yF2",
    "outputId": "73633e92-c286-43b9-d675-8707fa823d90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-21.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-21 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-21 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-21 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-21 .h2o-table th,\n",
       "#h2o-table-21 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-21 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-21\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>33 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>14 days, 12 hours and 44 minutes</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_unknownUser_ack7bq</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.170 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.12 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------------------------------------------------------------------\n",
       "H2O_cluster_uptime:         33 secs\n",
       "H2O_cluster_timezone:       Etc/UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.4\n",
       "H2O_cluster_version_age:    14 days, 12 hours and 44 minutes\n",
       "H2O_cluster_name:           H2O_from_python_unknownUser_ack7bq\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.170 Gb\n",
       "H2O_cluster_total_cores:    2\n",
       "H2O_cluster_allowed_cores:  2\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null, \"colab_language_server\": \"/usr/colab/bin/language_service\"}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.12 final\n",
       "--------------------------  -----------------------------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid SMILES: [*]OCC(CO[*])(CO[*])CO[*] |$_R1;;;;;;_R1;;;_R1;;;_R1$,lp:1:2,5:2,8:2,11:2,RG:_R1={*[H] |$_AP1;$|},{CCCCC(*)=O |$;;;;;_AP1;$,lp:6:2|},{CCCCCCCCC(*)=O |$;;;;;;;;;_AP1;$,lp:10:2|},{CCCCCCC(*)=O |$;;;;;;;_AP1;$,lp:8:2|}|\n",
      "Invalid SMILES: 0\n",
      "Invalid SMILES: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:55:26] SMILES Parse Error: syntax error while parsing: 0\n",
      "[08:55:26] SMILES Parse Error: Failed parsing SMILES '0' for input: '0'\n",
      "[08:55:26] SMILES Parse Error: syntax error while parsing: 0\n",
      "[08:55:26] SMILES Parse Error: Failed parsing SMILES '0' for input: '0'\n",
      "[08:55:26] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:55:26] WARNING: not removing hydrogen atom without neighbors\n",
      "[08:55:26] SMILES Parse Error: syntax error while parsing: 0\n",
      "[08:55:26] SMILES Parse Error: Failed parsing SMILES '0' for input: '0'\n",
      "[08:55:27] SMILES Parse Error: syntax error while parsing: 0\n",
      "[08:55:27] SMILES Parse Error: Failed parsing SMILES '0' for input: '0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid SMILES: 0\n",
      "Invalid SMILES: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:55:27] SMILES Parse Error: syntax error while parsing: 0\n",
      "[08:55:27] SMILES Parse Error: Failed parsing SMILES '0' for input: '0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid SMILES: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[08:55:27] SMILES Parse Error: syntax error while parsing: 0\n",
      "[08:55:27] SMILES Parse Error: Failed parsing SMILES '0' for input: '0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid SMILES: 0\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: | (failed)\n",
      "\n",
      "08:55:30.556: _train param, Dropping bad and constant columns: [Mol]\n",
      "08:55:30.556: _train param, Training data must have at least 2 features (incl. response).\n",
      "08:55:30.605: _train param, Dropping bad and constant columns: [Mol]\n",
      "08:55:30.605: _train param, Training data must have at least 2 features (incl. response).\n",
      "08:55:30.631: _train param, Dropping bad and constant columns: [Mol]\n",
      "08:55:30.631: _train param, Training data must have at least 2 features (incl. response).\n",
      "08:55:30.654: _train param, Dropping bad and constant columns: [Mol]\n",
      "08:55:30.655: _train param, Training data must have at least 2 features (incl. response).\n",
      "08:55:30.671: _train param, Dropping bad and constant columns: [Mol]\n",
      "08:55:30.671: _train param, Training data must have at least 2 features (incl. response).\n",
      "08:55:30.687: _train param, Dropping bad and constant columns: [Mol]\n",
      "08:55:30.687: _train param, Training data must have at least 2 features (incl. response).\n",
      "08:55:30.715: _train param, Dropping bad and constant columns: [Mol]\n",
      "08:55:30.715: _train param, Training data must have at least 2 features (incl. response).\n",
      "08:55:30.732: _train param, Dropping bad and constant columns: [Mol]\n",
      "08:55:30.732: _train param, Training data must have at least 2 features (incl. response).\n",
      "08:55:30.744: _train param, Dropping bad and constant columns: [Mol]\n",
      "08:55:30.744: _train param, Training data must have at least 2 features (incl. response).\n",
      "08:55:30.755: _train param, Dropping bad and constant columns: [Mol]\n",
      "08:55:30.755: _train param, Training data must have at least 2 features (incl. response).\n",
      "08:55:30.790: Empty leaderboard.\n",
      "AutoML was not able to build any model within a max runtime constraint of 0 seconds, you may want to increase this value before retrying.\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Job with key $03017f00000132d4ffffffff$_8ffdbcb908e239b44525ed97b5fc4989 failed with an exception: water.exceptions.H2OAutoMLException: Aborting AutoML after too many consecutive model failures\nstacktrace: \nwater.exceptions.H2OAutoMLException: Aborting AutoML after too many consecutive model failures\n\tat ai.h2o.automl.AutoML.learn(AutoML.java:776)\n\tat ai.h2o.automl.AutoML.run(AutoML.java:494)\n\tat ai.h2o.automl.H2OJob$1.compute2(H2OJob.java:33)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1704)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:976)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1479)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-daab374bfc87>\u001b[0m in \u001b[0;36m<cell line: 182>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-daab374bfc87>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;31m# Run AutoML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mautoml_runner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoMLRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mautoml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoml_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_fingerprints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# Create directory for saving model and results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-daab374bfc87>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fingerprints, activities)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mtarget_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Activity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mfeature_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Mol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh2o_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h2o/automl/_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, training_frame, fold_column, weights_column, validation_frame, leaderboard_frame, blending_frame)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0mpoll_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll_training_updates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verbosity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoll_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mpoll_updates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_job\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h2o/job.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, poll_updates)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"FAILED\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"stacktrace\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 raise EnvironmentError(\"Job with key {} failed with an exception: {}\\nstacktrace: \"\n\u001b[0m\u001b[1;32m     89\u001b[0m                                        \"\\n{}\".format(self.job_key, self.exception, self.job[\"stacktrace\"]))\n\u001b[1;32m     90\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Job with key $03017f00000132d4ffffffff$_8ffdbcb908e239b44525ed97b5fc4989 failed with an exception: water.exceptions.H2OAutoMLException: Aborting AutoML after too many consecutive model failures\nstacktrace: \nwater.exceptions.H2OAutoMLException: Aborting AutoML after too many consecutive model failures\n\tat ai.h2o.automl.AutoML.learn(AutoML.java:776)\n\tat ai.h2o.automl.AutoML.run(AutoML.java:494)\n\tat ai.h2o.automl.H2OJob$1.compute2(H2OJob.java:33)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1704)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:976)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1479)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\n"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from h2o.frame import H2OFrame\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, classification_report\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MACCSkeys, AllChem, RDKFingerprint\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class H2OManager:\n",
    "    def __init__(self):\n",
    "        self.h2o_instance = None\n",
    "\n",
    "    def initialize(self):\n",
    "        \"\"\"Initialize the H2O cluster.\"\"\"\n",
    "        self.h2o_instance = h2o.init()\n",
    "\n",
    "    def shutdown(self):\n",
    "        \"\"\"Shutdown the H2O cluster.\"\"\"\n",
    "        h2o.cluster().shutdown()\n",
    "\n",
    "class FingerprintGenerator:\n",
    "    def __init__(self, fingerprint_type):\n",
    "        self.fingerprint_type = fingerprint_type\n",
    "\n",
    "    def generate(self, mol):\n",
    "        \"\"\"Generate a fingerprint for a given molecule.\"\"\"\n",
    "        if not mol:\n",
    "            return None\n",
    "        if self.fingerprint_type == 'MACCS':\n",
    "            return MACCSkeys.GenMACCSKeys(mol)\n",
    "        elif self.fingerprint_type == 'Morgan':\n",
    "            return AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "        elif self.fingerprint_type == 'RDKit':\n",
    "            return RDKFingerprint(mol)\n",
    "        elif self.fingerprint_type == 'Layered':\n",
    "            return AllChem.LayeredFingerprint(mol)\n",
    "        elif self.fingerprint_type == 'Pattern':\n",
    "            return AllChem.PatternFingerprint(mol)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported fingerprint type: {self.fingerprint_type}\")\n",
    "\n",
    "    def generate_from_smiles(self, smiles_list, activities):\n",
    "        \"\"\"Generate fingerprints for the given SMILES list.\"\"\"\n",
    "        fingerprints = []\n",
    "        valid_activities = []\n",
    "        for smiles, activity in zip(smiles_list, activities):\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is None:\n",
    "                print(f\"Invalid SMILES: {smiles}\")\n",
    "                continue\n",
    "            fp = self.generate(mol)\n",
    "            if fp is not None:\n",
    "                fingerprints.append(fp.ToBitString())\n",
    "                valid_activities.append(activity)\n",
    "        return fingerprints, valid_activities\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def split_data(self):\n",
    "        \"\"\"Split the data into training and testing sets.\"\"\"\n",
    "        y = self.data['Toxicity'].values\n",
    "        X = self.data['SMILES'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    @staticmethod\n",
    "    def create_h2o_frame(fingerprints, activities):\n",
    "        \"\"\"Create an H2O frame from the given fingerprints and activities.\"\"\"\n",
    "        data_dict = {\n",
    "            'Mol': fingerprints,\n",
    "            'Activity': activities\n",
    "        }\n",
    "        return H2OFrame(pd.DataFrame(data_dict))\n",
    "\n",
    "class AutoMLRunner:\n",
    "    def __init__(self, max_models=20, seed=1):\n",
    "        self.max_models = max_models\n",
    "        self.seed = seed\n",
    "        self.automl = H2OAutoML(max_models=self.max_models, seed=self.seed, balance_classes=True)\n",
    "\n",
    "    def run(self, fingerprints, activities):\n",
    "        \"\"\"Run H2O AutoML on the given fingerprints and activities.\"\"\"\n",
    "        h2o_frame = DataProcessor.create_h2o_frame(fingerprints, activities)\n",
    "        h2o_frame['Activity'] = h2o_frame['Activity'].asfactor()  # Convert to categorical for classification\n",
    "        h2o_frame['Mol'] = h2o_frame['Mol'].ascharacter()  # Ensure Mol is treated as character\n",
    "        target_column = \"Activity\"\n",
    "        feature_columns = ['Mol']\n",
    "        self.automl.train(x=feature_columns, y=target_column, training_frame=h2o_frame)\n",
    "        return self.automl\n",
    "\n",
    "    def evaluate_and_save_model(self, automl, test_data, save_directory):\n",
    "        \"\"\"Evaluate the best model and save its performance metrics and plots.\"\"\"\n",
    "        best_model = automl.leader\n",
    "        performance = best_model.model_performance(test_data)\n",
    "        print(\"Performance on test data:\", performance)\n",
    "\n",
    "        # Calculate classification report\n",
    "        predictions = best_model.predict(test_data)\n",
    "        y_true = test_data['Activity'].as_data_frame()['Activity']\n",
    "        y_pred = predictions[\"predict\"].as_data_frame()['predict']\n",
    "        report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "        # Save metadata\n",
    "        metadata = {\n",
    "            \"model_path\": save_directory,\n",
    "            \"params\": best_model.get_params(),\n",
    "            \"performance\": performance.rmse(),\n",
    "            \"classification_report\": report,\n",
    "            \"timestamp\": (datetime.now(timezone(timedelta(hours=9)))).strftime(\"%Y%m%d_%H%M%S\")  # KST\n",
    "        }\n",
    "        metadata_path = os.path.join(save_directory, \"metadata.json\")\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(metadata, f)\n",
    "        print(f\"Metadata saved to: {metadata_path}\")\n",
    "\n",
    "        # Plot and save ROC curve\n",
    "        y_true_bin = (y_true == 1).astype(int)\n",
    "        y_pred_prob = predictions[\"p1\"].as_data_frame()['p1']\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin, y_pred_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:0.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(os.path.join(save_directory, \"roc_curve.png\"))\n",
    "        plt.show()\n",
    "\n",
    "def main():\n",
    "    h2o_manager = H2OManager()\n",
    "    h2o_manager.initialize()\n",
    "\n",
    "    # Example data load\n",
    "    data = pd.read_csv('/content/drive/MyDrive/H2O_AutoML/tg414.csv')\n",
    "    data_processor = DataProcessor(data)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = data_processor.split_data()\n",
    "\n",
    "    # Generate MACCS fingerprints\n",
    "    fingerprint_generator = FingerprintGenerator('MACCS')\n",
    "    train_fingerprints, y_train = fingerprint_generator.generate_from_smiles(X_train, y_train)\n",
    "    test_fingerprints, y_test = fingerprint_generator.generate_from_smiles(X_test, y_test)\n",
    "\n",
    "    # Ensure valid data length\n",
    "    min_length = min(len(train_fingerprints), len(y_train))\n",
    "    train_fingerprints = train_fingerprints[:min_length]\n",
    "    y_train = y_train[:min_length]\n",
    "\n",
    "    min_length = min(len(test_fingerprints), len(y_test))\n",
    "    test_fingerprints = test_fingerprints[:min_length]\n",
    "    y_test = y_test[:min_length]\n",
    "\n",
    "    # Run AutoML\n",
    "    automl_runner = AutoMLRunner()\n",
    "    automl = automl_runner.run(train_fingerprints, y_train)\n",
    "\n",
    "    # Create directory for saving model and results\n",
    "    current_time = datetime.now(timezone(timedelta(hours=9))).strftime(\"%Y%m%d_%H%M%S\")  # KST\n",
    "    save_directory = os.path.join(\"models\", current_time)\n",
    "    os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "    # Evaluate and save model\n",
    "    test_data_h2o = DataProcessor.create_h2o_frame(test_fingerprints, y_test)\n",
    "    test_data_h2o['Activity'] = test_data_h2o['Activity'].asfactor()  # Convert to categorical for classification\n",
    "    automl_runner.evaluate_and_save_model(automl, test_data_h2o, save_directory)\n",
    "\n",
    "    # Shutdown H2O cluster\n",
    "    h2o_manager.shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
